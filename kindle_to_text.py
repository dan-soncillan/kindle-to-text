#!/usr/bin/env python3
"""
kindle-to-text: Kindle Cloud Reader è‡ªå‹•ãƒšãƒ¼ã‚¸ã‚ãã‚Š + ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ + OCR

ä½¿ã„æ–¹:
    1. ãƒ–ãƒ©ã‚¦ã‚¶ã§ Kindle Cloud Reader ã‚’é–‹ãã€èª­ã¿ãŸã„æœ¬ã®æœ€åˆã®ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    2. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
    3. ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ä¸­ã«ãƒ–ãƒ©ã‚¦ã‚¶ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«åˆ‡ã‚Šæ›¿ãˆ
    4. è‡ªå‹•ã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ â†’ ãƒšãƒ¼ã‚¸ã‚ãã‚Š â†’ OCR â†’ ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›
"""

import argparse
import hashlib
import subprocess
import sys
import time
from pathlib import Path


def capture_screenshot(output_path: str, region: tuple[int, int, int, int] | None = None) -> None:
    """macOS screencapture ã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—"""
    cmd = ["screencapture", "-x"]  # -x: ç„¡éŸ³
    if region:
        x, y, w, h = region
        cmd.extend(["-R", f"{x},{y},{w},{h}"])
    cmd.append(str(output_path))
    subprocess.run(cmd, check=True)


def ocr_image(image_path: str, languages: list[str] | None = None) -> str:
    """macOS Vision framework ã§ OCR"""
    import Vision
    from Foundation import NSURL
    from Quartz import CGImageSourceCreateWithURL, CGImageSourceCreateImageAtIndex

    if languages is None:
        languages = ["ja", "en"]

    url = NSURL.fileURLWithPath_(str(image_path))
    source = CGImageSourceCreateWithURL(url, None)
    if not source:
        raise FileNotFoundError(f"ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“: {image_path}")

    cg_image = CGImageSourceCreateImageAtIndex(source, 0, None)
    if not cg_image:
        raise ValueError(f"ç”»åƒã®ä½œæˆã«å¤±æ•—: {image_path}")

    request = Vision.VNRecognizeTextRequest.alloc().init()
    request.setRecognitionLanguages_(languages)
    request.setRecognitionLevel_(Vision.VNRequestTextRecognitionLevelAccurate)

    handler = Vision.VNImageRequestHandler.alloc().initWithCGImage_options_(cg_image, None)
    success, error = handler.performRequests_error_([request], None)
    if not success:
        raise RuntimeError(f"OCRå¤±æ•—: {error}")

    lines = []
    for obs in request.results():
        candidates = obs.topCandidates_(1)
        if candidates:
            lines.append(candidates[0].string())
    return "\n".join(lines)


def images_match(path1: Path, path2: Path) -> bool:
    """2ã¤ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒåŒä¸€ã‹ãƒãƒƒã‚·ãƒ¥ã§æ¯”è¼ƒ"""
    return (
        hashlib.md5(path1.read_bytes()).hexdigest()
        == hashlib.md5(path2.read_bytes()).hexdigest()
    )


def turn_page(direction: str = "left") -> None:
    """çŸ¢å°ã‚­ãƒ¼ã§ãƒšãƒ¼ã‚¸ã‚ãã‚Šï¼ˆæ—¥æœ¬èªç¸¦æ›¸ã=left, è‹±èªæ¨ªæ›¸ã=rightï¼‰"""
    import pyautogui

    pyautogui.press(direction)


def countdown(seconds: int) -> None:
    """ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³è¡¨ç¤º"""
    print(f"\nâ³ {seconds}ç§’å¾Œã«é–‹å§‹ã—ã¾ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚")
    for i in range(seconds, 0, -1):
        print(f"  {i}...", flush=True)
        time.sleep(1)
    print("  é–‹å§‹ï¼\n")


def run_capture(args: argparse.Namespace) -> int:
    """ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå–å¾— + ãƒšãƒ¼ã‚¸ã‚ãã‚Š"""
    import pyautogui  # noqa: F401 â€” ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£æ¨©é™ã®æ—©æœŸãƒã‚§ãƒƒã‚¯

    region = None
    if args.region:
        parts = args.region.split(",")
        if len(parts) != 4:
            print("Error: --region ã¯ x,y,width,height å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„")
            return 1
        region = tuple(int(x.strip()) for x in parts)

    screenshots_dir = Path(args.screenshots_dir)
    screenshots_dir.mkdir(parents=True, exist_ok=True)

    countdown(args.countdown)

    max_pages = args.pages or 9999
    label = f"æœ€å¤§ {max_pages} ãƒšãƒ¼ã‚¸" if args.pages else "è‡ªå‹•åœæ­¢ãƒ¢ãƒ¼ãƒ‰"
    print(f"ğŸ“¸ ãƒšãƒ¼ã‚¸ã‚­ãƒ£ãƒ—ãƒãƒ£ä¸­... ({label})")

    captured = 0
    for i in range(max_pages):
        page_path = screenshots_dir / f"page_{i:04d}.png"
        capture_screenshot(str(page_path), region)
        captured += 1

        # å‰ãƒšãƒ¼ã‚¸ã¨æ¯”è¼ƒ â†’ åŒä¸€ãªã‚‰æœ€çµ‚ãƒšãƒ¼ã‚¸
        if i > 0:
            prev_path = screenshots_dir / f"page_{i - 1:04d}.png"
            if images_match(prev_path, page_path):
                page_path.unlink()
                captured -= 1
                print(f"  ğŸ æœ€çµ‚ãƒšãƒ¼ã‚¸æ¤œå‡º (page {captured})ã€‚åœæ­¢ã—ã¾ã™ã€‚")
                break

        print(f"  [{captured}/{max_pages if args.pages else '?'}] {page_path.name}", flush=True)

        if i < max_pages - 1:
            turn_page(args.direction)
            time.sleep(args.delay)

    print(f"\nâœ… ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå®Œäº†: {screenshots_dir}/ ({captured} ãƒšãƒ¼ã‚¸)")
    return captured


def run_ocr(screenshots_dir: Path, languages: list[str], output_file: str) -> None:
    """ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ OCR ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›"""
    image_files = sorted(screenshots_dir.glob("page_*.png"))
    if not image_files:
        print(f"Error: {screenshots_dir}/page_*.png ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)

    print(f"\nğŸ” OCRå‡¦ç†ä¸­... ({len(image_files)} ãƒšãƒ¼ã‚¸)")
    all_text = []
    for i, path in enumerate(image_files):
        print(f"  [{i + 1}/{len(image_files)}] {path.name}", flush=True)
        text = ocr_image(str(path), languages)
        all_text.append(text)

    output = Path(output_file)
    output.write_text("\n\n---\n\n".join(all_text), encoding="utf-8")
    total_chars = sum(len(t) for t in all_text)
    print(f"\nğŸ‰ å®Œäº†ï¼ {output} ({len(all_text)} ãƒšãƒ¼ã‚¸, {total_chars:,} æ–‡å­—)")


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Kindle Cloud Reader â†’ ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # æœ¬å…¨ä½“ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ + OCRï¼ˆè‡ªå‹•åœæ­¢ï¼‰
  uv run kindle_to_text.py

  # 100ãƒšãƒ¼ã‚¸åˆ†ã‚­ãƒ£ãƒ—ãƒãƒ£ + OCR
  uv run kindle_to_text.py --pages 100

  # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã ã‘å–å¾—ï¼ˆOCRã¯å¾Œã§ï¼‰
  uv run kindle_to_text.py --pages 50 --skip-ocr

  # æ—¢å­˜ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ OCR ã®ã¿å®Ÿè¡Œ
  uv run kindle_to_text.py --ocr-only

  # ç”»é¢ã®ç‰¹å®šé ˜åŸŸã ã‘ã‚­ãƒ£ãƒ—ãƒãƒ£
  uv run kindle_to_text.py --region 200,100,1200,800
        """,
    )
    parser.add_argument("--pages", type=int, default=None, help="ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹ãƒšãƒ¼ã‚¸æ•° (æœªæŒ‡å®šã§è‡ªå‹•åœæ­¢)")
    parser.add_argument("--delay", type=float, default=1.5, help="ãƒšãƒ¼ã‚¸ã‚ãã‚Šé–“ã®å¾…æ©Ÿç§’æ•° (default: 1.5)")
    parser.add_argument("--output", "-o", default="output.txt", help="å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (default: output.txt)")
    parser.add_argument("--region", type=str, default=None, help="ã‚­ãƒ£ãƒ—ãƒãƒ£é ˜åŸŸ x,y,width,height (ä¾‹: 200,100,1200,800)")
    parser.add_argument("--lang", default="ja,en", help="OCRè¨€èª (default: ja,en)")
    parser.add_argument("--countdown", type=int, default=5, help="é–‹å§‹å‰ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ç§’æ•° (default: 5)")
    parser.add_argument("--screenshots-dir", default="screenshots", help="ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜å…ˆ (default: screenshots/)")
    parser.add_argument("--direction", default="left", choices=["left", "right"], help="ãƒšãƒ¼ã‚¸ã‚ãã‚Šæ–¹å‘: left=æ—¥æœ¬èªç¸¦æ›¸ã, right=è‹±èªæ¨ªæ›¸ã (default: left)")
    parser.add_argument("--skip-ocr", action="store_true", help="ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®ã¿å–å¾— (OCRã‚¹ã‚­ãƒƒãƒ—)")
    parser.add_argument("--ocr-only", action="store_true", help="æ—¢å­˜ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰OCRã®ã¿å®Ÿè¡Œ")
    args = parser.parse_args()

    languages = [lang.strip() for lang in args.lang.split(",")]
    screenshots_dir = Path(args.screenshots_dir)

    if args.ocr_only:
        run_ocr(screenshots_dir, languages, args.output)
        return

    captured = run_capture(args)
    if captured == 0:
        print("ã‚­ãƒ£ãƒ—ãƒãƒ£ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    if not args.skip_ocr:
        run_ocr(screenshots_dir, languages, args.output)


if __name__ == "__main__":
    main()
